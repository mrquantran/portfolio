<!DOCTYPE html>
<html lang="en"><head><script src="/portfolio/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=portfolio/livereload" data-no-instant defer></script>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Building a Simple YOLOv10 Project for Object Detection</title>
    <meta charset="utf-8">
    <meta name="description" content="Ladder@Object detection has become an essential task in computer vision, enabling applications ranging from self-driving cars to security systems. One of the most popular frameworks for real-time object detection is YOLO (You Only Look Once). In this blog, we&rsquo;ll build a simple YOLOv10 project and explain why it works so effectively for object detection.
Introduction to YOLOv10 YOLO is a family of convolutional neural networks (CNN) designed for fast and accurate object detection.">
    <meta name="author" content="Quan, Tran Hong">
    <link rel="canonical" href="http://localhost:1313/portfolio/project/build_yolov10_object_detection/">
        <meta name="google-site-verification" content="xxx">

    <link rel="alternate" type="application/rss+xml" href="http://localhost:1313/portfolio//index.xml" title="quan">

    
<script async src="https://www.googletagmanager.com/gtag/js?id=G-xxx"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-xxx', { 'anonymize_ip': false });
}
</script>



<script async defer data-website-id="xxx" src="https://umami-ochre-nu.vercel.app/hugo-ladder.js"></script>

    <meta property="og:title" content="Building a Simple YOLOv10 Project for Object Detection" />
<meta property="og:description" content="Object detection has become an essential task in computer vision, enabling applications ranging from self-driving cars to security systems. One of the most popular frameworks for real-time object detection is YOLO (You Only Look Once). In this blog, we&rsquo;ll build a simple YOLOv10 project and explain why it works so effectively for object detection.
Introduction to YOLOv10 YOLO is a family of convolutional neural networks (CNN) designed for fast and accurate object detection." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/portfolio/project/build_yolov10_object_detection/" /><meta property="article:section" content="project" />
<meta property="article:published_time" content="2021-03-14T21:34:36+08:00" />
<meta property="article:modified_time" content="2021-03-14T21:34:36+08:00" />



<meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Building a Simple YOLOv10 Project for Object Detection"/>
<meta name="twitter:description" content="Object detection has become an essential task in computer vision, enabling applications ranging from self-driving cars to security systems. One of the most popular frameworks for real-time object detection is YOLO (You Only Look Once). In this blog, we&rsquo;ll build a simple YOLOv10 project and explain why it works so effectively for object detection.
Introduction to YOLOv10 YOLO is a family of convolutional neural networks (CNN) designed for fast and accurate object detection."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Projects",
      "item": "http://localhost:1313/portfolio/project/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Building a Simple YOLOv10 Project for Object Detection",
      "item": "http://localhost:1313/portfolio/project/build_yolov10_object_detection/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Building a Simple YOLOv10 Project for Object Detection",
  "name": "Building a Simple YOLOv10 Project for Object Detection",
  "description": "Object detection has become an essential task in computer vision, enabling applications ranging from self-driving cars to security systems. One of the most popular frameworks for real-time object detection is YOLO (You Only Look Once). In this blog, we\u0026rsquo;ll build a simple YOLOv10 project and explain why it works so effectively for object detection.\nIntroduction to YOLOv10 YOLO is a family of convolutional neural networks (CNN) designed for fast and accurate object detection.",
  "keywords": [
    "computer-vision", "ai-engineering"
  ],
  "articleBody": "Object detection has become an essential task in computer vision, enabling applications ranging from self-driving cars to security systems. One of the most popular frameworks for real-time object detection is YOLO (You Only Look Once). In this blog, we’ll build a simple YOLOv10 project and explain why it works so effectively for object detection.\nIntroduction to YOLOv10 YOLO is a family of convolutional neural networks (CNN) designed for fast and accurate object detection. Unlike traditional methods that apply the detection model to multiple regions of an image, YOLO treats object detection as a single regression problem, predicting bounding boxes and class probabilities directly from full images in one evaluation. YOLOv10, the latest iteration, introduces several improvements in architecture, leading to better performance and accuracy.\nWhy YOLOv10 Works for Object Detection Speed and Accuracy YOLOv10 is designed for real-time object detection, achieving high speed without compromising on accuracy. Its single-shot approach ensures that the entire image is processed in one pass, making it faster than region-based approaches.\nUnified Architecture The unified architecture of YOLOv10 simplifies the detection pipeline, reducing the computational complexity and improving efficiency. This model processes images using a single network, leading to faster inference times.\nImproved Bounding Box Predictions YOLOv10 incorporates advanced techniques for more accurate bounding box predictions, such as anchor boxes, which are predefined shapes that help the network learn to detect objects of various sizes and shapes more effectively.\nScalability The architecture of YOLOv10 is scalable, meaning it can be adapted to different hardware capabilities and specific application needs, from mobile devices to high-end GPUs.\nBuilding a Simple YOLOv10 Project Let’s build a simple YOLOv10 object detection project using Python and PyTorch. This project will involve setting up the environment, loading a pre-trained YOLOv10 model, and running inference on sample images.\nStep 1: Setting Up the Environment First, we need to install the necessary dependencies. Open a terminal and run the following commands:\n# Create a virtual environment python -m venv yolov10_env source yolov10_env/bin/activate # On Windows, use `yolov10_env\\Scripts\\activate` # Install PyTorch and other required libraries pip install torch torchvision pip install opencv-python Step 2: Downloading the Pre-trained YOLOv10 Model Next, we’ll download the pre-trained YOLOv10 model. For the purpose of this tutorial, we’ll use a simplified version available in the PyTorch Hub.\nimport torch # Load the pre-trained YOLOv10 model from PyTorch Hub model = torch.hub.load('ultralytics/yolov5', 'yolov5s') Step 3: Running Inference on Sample Images We’ll now run the model on some sample images to see it in action.\nimport cv2 import matplotlib.pyplot as plt # Load sample image image_path = 'path_to_your_image.jpg' img = cv2.imread(image_path) # Convert image to RGB img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Run inference results = model(img_rgb) # Display the results results.show() Step 4: Visualizing the Results The results.show() method will display the image with detected objects highlighted by bounding boxes. For more customized visualization, you can use Matplotlib to plot the results.\n# Extract bounding boxes and labels detections = results.xyxy[0].numpy() # Plot image with bounding boxes plt.imshow(img_rgb) ax = plt.gca() for detection in detections: xmin, ymin, xmax, ymax, confidence, class_id = detection rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False, edgecolor='red', linewidth=2) ax.add_patch(rect) label = f'{model.names[int(class_id)]}: {confidence:.2f}' plt.text(xmin, ymin, label, color='red', fontsize=12, bbox=dict(facecolor='yellow', alpha=0.5)) plt.axis('off') plt.show() Conclusion In this blog, we’ve built a simple YOLOv10 object detection project and explored why YOLOv10 is so effective for real-time object detection. Its speed, accuracy, and unified architecture make it a powerful tool for various applications. By following the steps outlined, you can start experimenting with YOLOv10 for your own object detection tasks.\nFeel free to customize the project, explore different datasets, and fine-tune the model for improved performance. Happy detecting!\n",
  "wordCount" : "611",
  "inLanguage": "en",
  "datePublished": "2021-03-14T21:34:36+08:00",
  "dateModified": "2021-03-14T21:34:36+08:00",
  "author":{
    "@type": "Person",
    "name": "Quan, Tran Hong"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/portfolio/project/build_yolov10_object_detection/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "quan",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/portfolio/favicon.ico"
    }
  }
}
</script>
    <link rel="icon" href="https://mrquantran.github.io/portfolio/images/favicon.png" sizes="16x16">

<link rel="apple-touch-icon" href="https://mrquantran.github.io/portfolio/images/favicon.png">

<link rel="manifest" href="https://mrquantran.github.io/portfolio/images/favicon.png">
    

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lxgw-wenkai-webfont@1.7.0/style.css" />

    
    
    
    <link rel="stylesheet" href="/portfolio/css/main.css" media="screen">
    


    
    <link rel="stylesheet" href="/portfolio/scss/highlight/github-dark.min.min.66034289ee9a113219a2c4aae0a8bd2095ab255c832a42efcf5863f10814e7a1.css" />

    
    <script src="/portfolio/js/highlight.min.min.c607d6febd16934a82eb61d3a896ed9d869f54373cc63ce95864ed5488fe3128.js"></script>
    <script>hljs.highlightAll();</script>


    <script>(()=>{var t=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,e=localStorage.getItem("theme");t&&e===null&&(localStorage.setItem("theme","dark"),document.documentElement.setAttribute("data-dark-mode","")),t&&e==="dark"&&document.documentElement.setAttribute("data-dark-mode",""),e==="dark"&&document.documentElement.setAttribute("data-dark-mode","")})()</script>
    </head>
<body>
      <main class="wrapper"><nav class="navigation">
    <section class="container">
        <a class="navigation-brand" href="/portfolio">
            <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-home"><path d="M3 9l9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"></path><polyline points="9 22 9 12 15 12 15 22"></polyline></svg>
        </a>
        <input type="checkbox" id="menu-toggle" />
        <label class="menu-button float-right" for="menu-toggle">
            <span></span><span></span><span></span>
        </label>
        
        <ul class="navigation-list" id="navigation-list">
            
            
            <li class="navigation-item navigation-menu">
                <a class="navigation-link" href="/portfolio/blog">Blog</a>
            </li>
            
            <li class="navigation-item navigation-menu">
                <a class="navigation-link" href="/portfolio/project">Project</a>
            </li>
            
            <li class="navigation-item navigation-menu">
                <a class="navigation-link" href="/portfolio/tags">Tags</a>
            </li>
            
            <li class="navigation-item navigation-menu">
                <a class="navigation-link" href="/portfolio/archives">Archive</a>
            </li>
            
            <li class="navigation-item navigation-menu">
                <a class="navigation-link" href="/portfolio/guestbook">Guestbook</a>
            </li>
            
            <li class="navigation-item navigation-menu">
                <a class="navigation-link" href="/portfolio/about">About</a>
            </li>
            
            

            <li class="navigation-item menu-separator">
                <span>|</span>
            </li>

            
            
            <li class="navigation-item navigation-social">
                <a class="navigation-link" href="https://github.com/mrquantran"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg></a>
            </li>
            
            <li class="navigation-item navigation-social">
                <a class="navigation-link" href="https://x.com/quantran2381"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-twitter"><path d="M23 3a10.9 10.9 0 0 1-3.14 1.53 4.48 4.48 0 0 0-7.86 3v1A10.66 10.66 0 0 1 3 4s-4 9 5 13a11.64 11.64 0 0 1-7 2c9 5 20 0 20-11.5a4.5 4.5 0 0 0-.08-.83A7.72 7.72 0 0 0 23 3z"></path></svg></a>
            </li>
            
            

            <li class="navigation-item navigation-dark">
                <button id="mode" type="button" aria-label="toggle user light or dark theme">
                    <span class="toggle-dark"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-moon"><path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path></svg></span>
                    <span class="toggle-light"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-sun"><circle cx="12" cy="12" r="5"></circle><line x1="12" y1="1" x2="12" y2="3"></line><line x1="12" y1="21" x2="12" y2="23"></line><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line><line x1="1" y1="12" x2="3" y2="12"></line><line x1="21" y1="12" x2="23" y2="12"></line><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line></svg></span>
                </button>
            </li>

            <li class="navigation-item navigation-dark">
                <button id="search-button" type="button" aria-label="toggle user light or dark theme">
                    <span class="toggle-dark"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"><circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line></svg></span>
                    <span class="toggle-light"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"><circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line></svg></span>
                </button>
            </li>

            
            
        </ul>
        
    </section>
</nav>




<div id="content">
<article class="blog-single">
  <header class="blog-title">
    <h1>Building a Simple YOLOv10 Project for Object Detection</h1>
  </header>

  <p>
  <small>
    March 14, 2021&nbsp;· 611 words&nbsp;· 3 min</small>

  <small>
      
      ·
      
      
      <a href="http://localhost:1313/portfolio/tags/computer-vision/">Computer-Vision</a>
      
      <a href="http://localhost:1313/portfolio/tags/ai-engineering/">Ai-Engineering</a>
      
    </small>
  
<p>

  <div class="blog-toc">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#introduction-to-yolov10">Introduction to YOLOv10</a></li>
    <li><a href="#why-yolov10-works-for-object-detection">Why YOLOv10 Works for Object Detection</a>
      <ul>
        <li><a href="#speed-and-accuracy">Speed and Accuracy</a></li>
        <li><a href="#unified-architecture">Unified Architecture</a></li>
        <li><a href="#improved-bounding-box-predictions">Improved Bounding Box Predictions</a></li>
        <li><a href="#scalability">Scalability</a></li>
      </ul>
    </li>
    <li><a href="#building-a-simple-yolov10-project">Building a Simple YOLOv10 Project</a>
      <ul>
        <li><a href="#step-1-setting-up-the-environment">Step 1: Setting Up the Environment</a></li>
        <li><a href="#step-2-downloading-the-pre-trained-yolov10-model">Step 2: Downloading the Pre-trained YOLOv10 Model</a></li>
        <li><a href="#step-3-running-inference-on-sample-images">Step 3: Running Inference on Sample Images</a></li>
        <li><a href="#step-4-visualizing-the-results">Step 4: Visualizing the Results</a></li>
      </ul>
    </li>
    <li><a href="#conclusion">Conclusion</a></li>
  </ul>
</nav>
  </div>

  <section class="blog-content"><p>Object detection has become an essential task in computer vision, enabling applications ranging from self-driving cars to security systems. One of the most popular frameworks for real-time object detection is YOLO (You Only Look Once). In this blog, we&rsquo;ll build a simple YOLOv10 project and explain why it works so effectively for object detection.</p>
<h2 id="introduction-to-yolov10">Introduction to YOLOv10</h2>
<p>YOLO is a family of convolutional neural networks (CNN) designed for fast and accurate object detection. Unlike traditional methods that apply the detection model to multiple regions of an image, YOLO treats object detection as a single regression problem, predicting bounding boxes and class probabilities directly from full images in one evaluation. YOLOv10, the latest iteration, introduces several improvements in architecture, leading to better performance and accuracy.</p>
<h2 id="why-yolov10-works-for-object-detection">Why YOLOv10 Works for Object Detection</h2>
<h3 id="speed-and-accuracy">Speed and Accuracy</h3>
<p>YOLOv10 is designed for real-time object detection, achieving high speed without compromising on accuracy. Its single-shot approach ensures that the entire image is processed in one pass, making it faster than region-based approaches.</p>
<h3 id="unified-architecture">Unified Architecture</h3>
<p>The unified architecture of YOLOv10 simplifies the detection pipeline, reducing the computational complexity and improving efficiency. This model processes images using a single network, leading to faster inference times.</p>
<h3 id="improved-bounding-box-predictions">Improved Bounding Box Predictions</h3>
<p>YOLOv10 incorporates advanced techniques for more accurate bounding box predictions, such as anchor boxes, which are predefined shapes that help the network learn to detect objects of various sizes and shapes more effectively.</p>
<h3 id="scalability">Scalability</h3>
<p>The architecture of YOLOv10 is scalable, meaning it can be adapted to different hardware capabilities and specific application needs, from mobile devices to high-end GPUs.</p>
<h2 id="building-a-simple-yolov10-project">Building a Simple YOLOv10 Project</h2>
<p>Let&rsquo;s build a simple YOLOv10 object detection project using Python and PyTorch. This project will involve setting up the environment, loading a pre-trained YOLOv10 model, and running inference on sample images.</p>
<h3 id="step-1-setting-up-the-environment">Step 1: Setting Up the Environment</h3>
<p>First, we need to install the necessary dependencies. Open a terminal and run the following commands:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Create a virtual environment</span>
</span></span><span style="display:flex;"><span>python -m venv yolov10_env
</span></span><span style="display:flex;"><span>source yolov10_env/bin/activate  <span style="color:#75715e"># On Windows, use `yolov10_env\Scripts\activate`</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Install PyTorch and other required libraries</span>
</span></span><span style="display:flex;"><span>pip install torch torchvision
</span></span><span style="display:flex;"><span>pip install opencv-python
</span></span></code></pre></div><h3 id="step-2-downloading-the-pre-trained-yolov10-model">Step 2: Downloading the Pre-trained YOLOv10 Model</h3>
<p>Next, we&rsquo;ll download the pre-trained YOLOv10 model. For the purpose of this tutorial, we&rsquo;ll use a simplified version available in the PyTorch Hub.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Load the pre-trained YOLOv10 model from PyTorch Hub</span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>hub<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#39;ultralytics/yolov5&#39;</span>, <span style="color:#e6db74">&#39;yolov5s&#39;</span>)
</span></span></code></pre></div><h3 id="step-3-running-inference-on-sample-images">Step 3: Running Inference on Sample Images</h3>
<p>We&rsquo;ll now run the model on some sample images to see it in action.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> cv2
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Load sample image</span>
</span></span><span style="display:flex;"><span>image_path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;path_to_your_image.jpg&#39;</span>
</span></span><span style="display:flex;"><span>img <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>imread(image_path)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Convert image to RGB</span>
</span></span><span style="display:flex;"><span>img_rgb <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>cvtColor(img, cv2<span style="color:#f92672">.</span>COLOR_BGR2RGB)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Run inference</span>
</span></span><span style="display:flex;"><span>results <span style="color:#f92672">=</span> model(img_rgb)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Display the results</span>
</span></span><span style="display:flex;"><span>results<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><h3 id="step-4-visualizing-the-results">Step 4: Visualizing the Results</h3>
<p>The <code>results.show()</code> method will display the image with detected objects highlighted by bounding boxes. For more customized visualization, you can use Matplotlib to plot the results.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Extract bounding boxes and labels</span>
</span></span><span style="display:flex;"><span>detections <span style="color:#f92672">=</span> results<span style="color:#f92672">.</span>xyxy[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>numpy()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Plot image with bounding boxes</span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>imshow(img_rgb)
</span></span><span style="display:flex;"><span>ax <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>gca()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> detection <span style="color:#f92672">in</span> detections:
</span></span><span style="display:flex;"><span>    xmin, ymin, xmax, ymax, confidence, class_id <span style="color:#f92672">=</span> detection
</span></span><span style="display:flex;"><span>    rect <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>Rectangle((xmin, ymin), xmax <span style="color:#f92672">-</span> xmin, ymax <span style="color:#f92672">-</span> ymin, fill<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>, edgecolor<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;red&#39;</span>, linewidth<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>    ax<span style="color:#f92672">.</span>add_patch(rect)
</span></span><span style="display:flex;"><span>    label <span style="color:#f92672">=</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">{</span>model<span style="color:#f92672">.</span>names[int(class_id)]<span style="color:#e6db74">}</span><span style="color:#e6db74">: </span><span style="color:#e6db74">{</span>confidence<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>
</span></span><span style="display:flex;"><span>    plt<span style="color:#f92672">.</span>text(xmin, ymin, label, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;red&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">12</span>, bbox<span style="color:#f92672">=</span>dict(facecolor<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;yellow&#39;</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>axis(<span style="color:#e6db74">&#39;off&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><h2 id="conclusion">Conclusion</h2>
<p>In this blog, we&rsquo;ve built a simple YOLOv10 object detection project and explored why YOLOv10 is so effective for real-time object detection. Its speed, accuracy, and unified architecture make it a powerful tool for various applications. By following the steps outlined, you can start experimenting with YOLOv10 for your own object detection tasks.</p>
<p>Feel free to customize the project, explore different datasets, and fine-tune the model for improved performance. Happy detecting!</p>
</section>

  
  

  

<div class="related-resources">
  
    
    
    
  
</div>


  
<div class="comments">
  <script>
      const getTheme = window.localStorage && window.localStorage.getItem("theme");
      let theme = getTheme === 'dark' ? 'github-dark' : 'github-light';
      let s = document.createElement('script');
      s.src = 'https://utteranc.es/client.js';
      s.setAttribute('repo', 'mrquantran\/portfolio');
      s.setAttribute('issue-term', 'pathname');
      s.setAttribute('theme', theme);
      s.setAttribute('crossorigin', 'anonymous');
      s.setAttribute('async', '');
      document.querySelector('div.comments').innerHTML = '';
      document.querySelector('div.comments').appendChild(s);
  </script>
</div>

  
</article>

<div
  id="search-wrapper"
  class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]"
  data-url="http://localhost:1313/portfolio/"
  style="z-index:500"
>
  <div
    id="search-modal"
    class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"
  >
    <header class="relative z-10 flex items-center justify-between flex-none px-2">
      <form class="flex items-center flex-auto min-w-0">
    
        <input
          type="search"
          id="search-query"
          class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent"
          placeholder=""
          tabindex="0"
        />
      </form>
      
      <button
        type="button"
        id="close-search-button"
        title=""
      >
            <span class="toggle-dark"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-x"><line x1="18" y1="6" x2="6" y2="18"></line><line x1="6" y1="6" x2="18" y2="18"></line></svg></span>
      </button>
    </header>
    <section class="flex-auto px-2 overflow-auto">
      <ul id="search-results">
        
      </ul>
    </section>
  </div>
</div>
</div><footer class="footer">
  <p>&copy; 2024 <a href="http://localhost:1313/portfolio/">quan</a>
    Powered by
    <a href="https://gohugo.io/" rel="noopener" target="_blank">Hugo️️</a>
    <a href="https://github.com/guangzhengli/hugo-theme-ladder" rel="noopener" target="_blank">Ladder</a>
️  </p>
</footer>

<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M10.5376 22.7916C11.0152 22.7207 22.5795 21.1781 22.0978 10.4211C22.0536 9.43274 21.9303 8.53367 21.7387 7.71865M10.5376 22.7916C16.876 22.3728 20.0969 19.8899 21.5383 16.9142M10.5376 22.7916C9.7707 22.9055 8.97982 22.8964 8.19743 22.7725M21.7387 7.71865C21.4988 6.69828 21.1518 5.80967 20.7188 5.04257M21.7387 7.71865C22.6022 10.1105 23.0542 13.7848 21.5383 16.9142M20.7188 5.04257C17.1684 -1.24629 7.83127 0.632493 4.27577 5.04257C2.88063 6.77451 -0.0433281 11.1668 1.38159 16.6571C2.27481 20.0988 5.17269 22.2936 8.19743 22.7725M20.7188 5.04257C22.0697 6.9404 24.0299 11.3848 22.3541 15.4153M21.5383 16.9142C21.8737 16.4251 22.1428 15.9235 22.3541 15.4153M8.19743 22.7725C12.1971 23.4683 20.6281 22.971 22.3541 15.4153M14 10.945C13.3836 10.289 12.003 8.63215 11.2034 7.04814C11.1703 6.98257 11.0247 6.98456 10.9937 7.05061C10.5221 8.05496 9.07362 9.92941 8 10.945M11.0333 7.44444C10.9392 9.86549 11 15 12 17" stroke="currentColor" stroke-linecap="round"/>
    </svg>
</a>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };
</script>


<script src="/portfolio/js/fuse.min.min.9c77fe122996bc57fcc9465a469d9e5b917054338cc16807bbedb39f36d0a37f.js"></script>
    

<script src="/portfolio/js/search.min.ae447e970eb58b3fa26b06a8fabecd6d2fa462af0e70dd8cf6298cef271506a7.js"></script>

<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'Copy';

        function copyingDone() {
            copybutton.innerHTML = 'Copied';
            setTimeout(() => {
                copybutton.innerHTML = 'Copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });
        codeblock.parentNode.appendChild(copybutton);
    });
</script></main>
    </body><script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.6/medium-zoom.min.js" integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

  <script>
      const images = Array.from(document.querySelectorAll(".blog-content img"));
      images.forEach(img => {
          mediumZoom(img, {
              margin: 10,  
              scrollOffset: 40,  
              container: null,  
              template: null,  
              background: 'rgba(0, 0, 0, 0.5)'
          });
      });
  </script>

  
  <script src="/portfolio/main.min.6bb26b69159420159c74dc9e097b06a578ed2b68c701466a91a44a9632d851bd0af167a1b30012387b4c512b48ad9ad4d3394e04d77ae38d57e1920fe4ed34fe.js" integrity="sha512-a7JraRWUIBWcdNyeCXsGpXjtK2jHAUZqkaRKljLYUb0K8WehswASOHtMUStIrZrU0zlOBNd6441X4ZIP5O00/g==" crossorigin="anonymous" defer></script></html>
